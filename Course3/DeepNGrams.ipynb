{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hh = np.random.standard_normal((3,2))\n",
    "w_hx = np.random.standard_normal((3,3))\n",
    "h_t_prev = np.random.standard_normal((2,1))\n",
    "x_t = np.random.standard_normal((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_1 = np.hstack((w_hh, w_hx))\n",
    "\n",
    "stack_2 = np.vstack((h_t_prev, x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32319683]\n",
      " [-0.6577149 ]\n",
      " [ 4.61825108]]\n",
      "[[ 0.32319683]\n",
      " [-0.6577149 ]\n",
      " [ 4.61825108]]\n",
      "[[-0.56228753]\n",
      " [-1.01283112]\n",
      " [ 0.31424733]\n",
      " [-0.90802408]\n",
      " [-1.4123037 ]]\n",
      "[[-0.56228753]\n",
      " [-1.01283112]\n",
      " [ 0.31424733]\n",
      " [-0.90802408]\n",
      " [-1.4123037 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t))))\n",
    "print(np.matmul(stack_1,stack_2))\n",
    "print(stack_2)\n",
    "print(np.concatenate([h_t_prev, x_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:57:07.102889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-16 18:57:07.126617: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-16 18:57:07.133171: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-16 18:57:07.149998: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 18:57:08.209878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from time import perf_counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)                 # Random seed, so your results match ours\n",
    "emb = 128                       # Embedding size\n",
    "T = 256                         # Length of sequence\n",
    "h_dim = 16                      # Hidden state dimension\n",
    "h_0 = np.zeros((h_dim, 1))     \n",
    " \n",
    "w1 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w2 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w3 = random.standard_normal((h_dim, emb + h_dim))\n",
    "\n",
    "b1 = random.standard_normal((h_dim, 1))\n",
    "b2 = random.standard_normal((h_dim, 1))\n",
    "b3 = random.standard_normal((h_dim, 1))\n",
    "\n",
    "X = random.standard_normal((T, emb, 1))\n",
    "\n",
    "weights_vanilla = [w1, b1]\n",
    "weights_GRU = [w1.copy(), w2, w3, b1.copy(), b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_RNN(inputs, weights):\n",
    "    x, ht = inputs\n",
    "    wh, bh = weights\n",
    "    \n",
    "    ht = np.matmul(wh, np.vstack((ht, x)))+bh\n",
    "    ht = sigmoid(ht)\n",
    "\n",
    "    y = ht\n",
    "    #print(ht)\n",
    "    return y,ht \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_GRU_RNN(inputs, weights):\n",
    "    x, ht = inputs\n",
    "    wu,wr,wh, bu,br,bh = weights\n",
    "\n",
    "    r = sigmoid(np.matmul(wr, np.vstack((ht, x)))+br)\n",
    "    u = sigmoid(np.matmul(wu, np.vstack((ht, x)))+bu)\n",
    "    ct = np.tanh(np.matmul(wh, np.concatenate([r * ht, x]))+bh)\n",
    "\n",
    "    #print(f'{u}\\n+\\n{r}\\n+\\n{ct}')\n",
    "    \n",
    "    ht = u*ct + (1-u) * ht\n",
    "    y = ht\n",
    "\n",
    "    return y,ht \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 9.77779014e-01],\n",
      "       [-9.97986240e-01],\n",
      "       [-5.19958083e-01],\n",
      "       [-9.99999886e-01],\n",
      "       [-9.99707004e-01],\n",
      "       [-3.02197037e-04],\n",
      "       [-9.58733503e-01],\n",
      "       [ 2.10804828e-02],\n",
      "       [ 9.77365398e-05],\n",
      "       [ 9.99833090e-01],\n",
      "       [ 1.63200940e-08],\n",
      "       [ 8.51874303e-01],\n",
      "       [ 5.21399924e-02],\n",
      "       [ 2.15495959e-02],\n",
      "       [ 9.99878828e-01],\n",
      "       [ 9.77165472e-01]]), array([[ 9.77779014e-01],\n",
      "       [-9.97986240e-01],\n",
      "       [-5.19958083e-01],\n",
      "       [-9.99999886e-01],\n",
      "       [-9.99707004e-01],\n",
      "       [-3.02197037e-04],\n",
      "       [-9.58733503e-01],\n",
      "       [ 2.10804828e-02],\n",
      "       [ 9.77365398e-05],\n",
      "       [ 9.99833090e-01],\n",
      "       [ 1.63200940e-08],\n",
      "       [ 8.51874303e-01],\n",
      "       [ 5.21399924e-02],\n",
      "       [ 2.15495959e-02],\n",
      "       [ 9.99878828e-01],\n",
      "       [ 9.77165472e-01]]))\n"
     ]
    }
   ],
   "source": [
    "print(forward_GRU_RNN([X[1], h_0], weights_GRU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(function, elems, weights, initializer=h_0):\n",
    "    cur_value = initializer\n",
    "    ys = []\n",
    "    for x in elems:\n",
    "        y,cur_value = function([x,cur_value],weights)\n",
    "        ys.append(y)\n",
    "    return ys,cur_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ys: 256\n",
      "Shape of each y within ys: (16, 1)\n",
      "Shape of h_T: (16, 1)\n"
     ]
    }
   ],
   "source": [
    "ys, h_T = scan(forward_RNN, X, weights_vanilla, h_0)\n",
    "\n",
    "print(f\"Length of ys: {len(ys)}\")\n",
    "print(f\"Shape of each y within ys: {ys[0].shape}\")\n",
    "print(f\"Shape of h_T: {h_T.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 9.86ms to run the forward method for the vanilla RNN.\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_RNN, X, weights_vanilla, h_0)\n",
    "toc = perf_counter()\n",
    "RNN_time=(toc-tic)*1000\n",
    "print (f\"It took {RNN_time:.2f}ms to run the forward method for the vanilla RNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 15.43ms to run the forward method for the GRU.\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_GRU_RNN, X, weights_GRU, h_0)\n",
    "toc = perf_counter()\n",
    "GRU_time=(toc-tic)*1000\n",
    "print (f\"It took {GRU_time:.2f}ms to run the forward method for the GRU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721181429.023349  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.068600  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.068810  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.070333  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.070515  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.070673  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.150115  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.150321  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721181429.150493  251028 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-16 18:57:09.150673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5561 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model_GRU = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(256, return_sequences=True, name='GRU_1_returns_seq'),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, name='GRU_2_returns_seq'),\n",
    "    tf.keras.layers.GRU(64, name='GRU_3_returns_last_only'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (\u001b[38;5;33mGRU\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    model_GRU.summary()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:57:09.551793: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">228,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │       \u001b[38;5;34m228,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m148,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (\u001b[38;5;33mGRU\u001b[0m)   │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,986</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m414,986\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,986</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m414,986\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember these three numbers and follow them further through the notebook\n",
    "batch_size = 60\n",
    "sequence_length = 50\n",
    "word_vector_length = 40\n",
    "\n",
    "input_data = tf.random.normal([batch_size, sequence_length, word_vector_length])\n",
    "\n",
    "prediction = model_GRU(input_data)\n",
    "\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "BENVOLIO\tHere were the servants of your adversary,\n",
      "And yours, close fighting ere I did approach:\n",
      "I drew to part them: in the instant came\n",
      "The fiery Tybalt, with his sword prepared,\n",
      "Which, as he breathed defiance to my ears,\n",
      "He swung about his head and cut the winds,\n",
      "Who nothing hurt withal hiss'd him in scorn:\n",
      "While we were interchanging thrusts and blows,\n"
     ]
    }
   ],
   "source": [
    "dirname = 'data/'\n",
    "filename = 'shakespeare_data.txt'\n",
    "lines = [] # storing all the lines in a variable. \n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(os.path.join(dirname, filename)) as files:\n",
    "    for line in files:        \n",
    "        pure_line = line.strip()\n",
    "        if pure_line:\n",
    "            lines.append(pure_line)\n",
    "            \n",
    "n_lines = len(lines)\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(\"\\n\".join(lines[506:514]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "[UNK]  \t \n",
      "   ! $ & ' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z |\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(lines):\n",
    "    corpus = (\"\\n\".join(lines))\n",
    "    vocab = sorted(set(corpus))\n",
    "    vocab.insert(0,\"[UNK]\") \n",
    "    vocab.insert(1,\"\") \n",
    "    return vocab\n",
    "vocab = build_vocabulary(lines)\n",
    "print(len(vocab))\n",
    "print(\" \".join(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([55 56 57  4 78 79 80], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def convert_text_to_tensor(text,vocab):\n",
    "    chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\n",
    "    return  tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)(chars)\n",
    "tmp = convert_text_to_tensor(\"abc xyz\", vocab)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'abc xyz'\n"
     ]
    }
   ],
   "source": [
    "def convert_tensor_to_text(tensor, vocab):\n",
    "    chars_from_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None, invert=True)\n",
    "    return tf.strings.reduce_join(chars_from_ids(tensor), axis=-1).numpy()\n",
    "print(convert_tensor_to_text(tmp, vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = lines[:-1000]\n",
    "eval_lines = lines[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'], ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(sequence):\n",
    "    return sequence[:-1], sequence[1:]\n",
    "print(test_train_split(list(\"Tensorflow\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(vocab, lines, seq_length=100, batch_size=64, BUFFER_SIZE = 10000):\n",
    "\n",
    "    line  = \"\\n\".join(lines)\n",
    "    all_ids = convert_text_to_tensor(line, vocab)\n",
    "    ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "    data_generator = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "    dataset_xy = data_generator.map(test_train_split)\n",
    "    dataset = (                                   \n",
    "        dataset_xy                                \n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(batch_size, drop_remainder=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "        )            \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = generate_dataset(vocab, train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size, activation=tf.nn.log_softmax)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "vocab_size = 82  # Adjust as needed\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "model = create_gru_model(vocab_size, embedding_dim, rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,050</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m82\u001b[0m)        │        \u001b[38;5;34m84,050\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,043,346</span> (15.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,043,346\u001b[0m (15.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,043,346</span> (15.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,043,346\u001b[0m (15.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 100))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [ 3 39 55 73 65 73  4 60 69 72  4 60 55 57 59 73  4 55 68 58  4 60 69 72\n",
      "  4 68 69 73 59 73 25  3 28 75 61 66 59  4 56 72 55 57 59 66 59 74 11  4\n",
      " 68 59 57 65 66 55 57 59  4 55 67 56 59 72 11  3 42 59 72 60 75 67 59  4\n",
      " 60 69 72  4 55  4 66 55 58 79  8 73  4 57 62 55 67 56 59 72 25  3 33 69\n",
      " 66 58 59 68]\n",
      "\n",
      " (1, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:57:15.190813: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input: \", input_example_batch[0].numpy()) # Lets use only the first sequence on the batch\n",
    "    example_batch_predictions = model(tf.constant([input_example_batch[0].numpy()]))\n",
    "    print(\"\\n\",example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.4130692, -4.416311 , -4.4016833, -4.410658 , -4.4067287,\n",
       "       -4.3992157, -4.4210277, -4.407576 , -4.4139214, -4.396899 ,\n",
       "       -4.396371 , -4.4084687, -4.407805 , -4.423681 , -4.416815 ,\n",
       "       -4.419162 , -4.4033084, -4.405543 , -4.393971 , -4.4030976,\n",
       "       -4.4075236, -4.4005265, -4.412947 , -4.4052925, -4.406697 ,\n",
       "       -4.390149 , -4.4055448, -4.4109864, -4.397797 , -4.4068136,\n",
       "       -4.384658 , -4.420477 , -4.418874 , -4.414543 , -4.419545 ,\n",
       "       -4.4037094, -4.4163322, -4.4001765, -4.410797 , -4.411979 ,\n",
       "       -4.4173183, -4.4164767, -4.3829775, -4.399707 , -4.4190474,\n",
       "       -4.4072313, -4.413683 , -4.392843 , -4.414936 , -4.405369 ,\n",
       "       -4.3996434, -4.3936777, -4.404102 , -4.3984213, -4.3938465,\n",
       "       -4.406202 , -4.4059267, -4.4067974, -4.3892555, -4.393785 ,\n",
       "       -4.396074 , -4.4068847, -4.4093714, -4.4166293, -4.4203515,\n",
       "       -4.402825 , -4.4240513, -4.406167 , -4.3970575, -4.415121 ,\n",
       "       -4.400227 , -4.4143405, -4.4084506, -4.384723 , -4.4136443,\n",
       "       -4.4055367, -4.4110556, -4.403595 , -4.4136376, -4.4118695,\n",
       "       -4.414317 , -4.406627 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0][99].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71 75 12 59 57 57  3  3 80 80 80 59 12 72 58 59  3 64 30 73 80 59 80 80\n",
      " 80 51 80 80 57 57 64 71 42 59  7 79 26 53 53 51 64 72 58 79 26  5 46 80\n",
      " 30 42 69 58  9 58 72 58 10 58 69  2 26 50 46 20 66 42 50 59 59 69 26  3\n",
      " 34 80 80 80  3  3 53 14 59 71 59 59  3 22 37 14 12  2 26 50 35 20 51 80\n",
      " 80 80 26 42]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.math.argmax(example_batch_predictions[0], axis=1)\n",
    "print(sampled_indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"\\nMasks for faces and for noses;\\nBugle bracelet, necklace amber,\\nPerfume for a lady's chamber;\\nGolden\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'qu-ecc\\n\\nzzze-rde\\njDszezzzYzzccjqPe&y?[[Yjrdy?!TzDPod(drd)do\\t?XT6lPXeeo?\\nHzzz\\n\\n[0eqee\\n8K0-\\t?XI6Yzzz?P'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", convert_tensor_to_text(input_example_batch[0], vocab))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", convert_tensor_to_text(sampled_indices, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00125)\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 39ms/step - loss: 2.2383\n",
      "Epoch 2/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 38ms/step - loss: 1.4186\n",
      "Epoch 3/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 37ms/step - loss: 1.3195\n",
      "Epoch 4/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.2717\n",
      "Epoch 5/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.2393\n",
      "Epoch 6/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.2142\n",
      "Epoch 7/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.1942\n",
      "Epoch 8/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.1775\n",
      "Epoch 9/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 35ms/step - loss: 1.1641\n",
      "Epoch 10/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 36ms/step - loss: 1.1535\n",
      "Epoch 11/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 36ms/step - loss: 1.1452\n",
      "Epoch 12/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 36ms/step - loss: 1.1401\n",
      "Epoch 13/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 37ms/step - loss: 1.1365\n",
      "Epoch 14/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 31ms/step - loss: 1.1347\n",
      "Epoch 15/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1340\n",
      "Epoch 16/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1352\n",
      "Epoch 17/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1398\n",
      "Epoch 18/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1429\n",
      "Epoch 19/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1570\n",
      "Epoch 20/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1731\n",
      "Epoch 21/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.1766\n",
      "Epoch 22/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.2285\n",
      "Epoch 23/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.2599\n",
      "Epoch 24/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.8700\n",
      "Epoch 25/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.6728\n",
      "Epoch 26/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.5819\n",
      "Epoch 27/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.5136\n",
      "Epoch 28/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.4621\n",
      "Epoch 29/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.4198\n",
      "Epoch 30/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 29ms/step - loss: 1.3893\n"
     ]
    }
   ],
   "source": [
    "Epochs = 30\n",
    "model = compile_model(model)\n",
    "history = model.fit(dataset, epochs = Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"saved.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"saved.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,050</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)      │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m82\u001b[0m)        │        \u001b[38;5;34m84,050\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,130,040</span> (46.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,130,040\u001b[0m (46.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,043,346</span> (15.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,043,346\u001b[0m (15.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,086,694</span> (30.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m8,086,694\u001b[0m (30.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [75 72  4 77 63 66 66  4 56 59  4 58 69 68 59 24  4 74 62 63 73  4 67 75\n",
      " 73 74  4 67 79  4 57 69 67 60 69 72 74  4 56 59 11  3 45 75 68  4 74 62\n",
      " 55 74  4 77 55 72 67 73  4 79 69 75  4 62 59 72 59  4 73 62 55 66 66  4\n",
      " 73 62 63 68 59  4 69 68  4 67 59 25  3 27 68 58  4 74 62 69 73 59  4 62\n",
      " 63 73  4 61]\n",
      "\n",
      " (1, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 19:10:30.299690: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input: \", input_example_batch[0].numpy()) # Lets use only the first sequence on the batch\n",
    "    example_batch_predictions = model(tf.constant([input_example_batch[0].numpy()]))\n",
    "    print(\"\\n\",example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72  4 60 63 74 66  4 56 59  4 73 59 68 59  4  3 35 62 59 73  4 63 69 73\n",
      " 63  4 35 55  4 62 69 75 70 69 72 74  4 63 59  4  3 46 69 57  4 74 62 59\n",
      " 74  4 35 59 73 73  4  4 62 69 75 72 55 55 72 59  4 55 69 59 66 66  4 73\n",
      " 59 55 68 59  4 69 60  4 74 59  4  3 27 68 58  4 74 62 59 75 59  4 74 59\n",
      " 73  4 70 72]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.math.argmax(example_batch_predictions[0], axis=1)\n",
    "print(sampled_indices.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'ur will be done: this must my comfort be,\\nSun that warms you here shall shine on me;\\nAnd those his g'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'r fitl be sene \\nIhes iosi Ia houport ie \\nToc thet Iess  houraare aoell seane of te \\nAnd theue tes pr'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", convert_tensor_to_text(input_example_batch[0], vocab))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", convert_tensor_to_text(sampled_indices, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_text(model, vocab, starter_word, num_chars_to_generate=100, temperature=0.001):\n",
    "    # Initialize the text with the starter word\n",
    "    generated_text = starter_word\n",
    "    input_eval = convert_text_to_tensor(starter_word, vocab)\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Generate characters\n",
    "    for _ in range(num_chars_to_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = predictions[:, -1, :] / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # Convert the predicted ID to a character and add to the generated text\n",
    "        predicted_char = vocab[predicted_id]\n",
    "        generated_text += predicted_char\n",
    "\n",
    "        # Update the input for the next prediction\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to be s t and are t ar the and wo wid and s s in hour ange an anghe s an s the histhe the g me ind the wi\n"
     ]
    }
   ],
   "source": [
    "starter_word = \"to be\"\n",
    "generated_text = generate_text(model, vocab, starter_word, num_chars_to_generate=100, temperature=0.4)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
