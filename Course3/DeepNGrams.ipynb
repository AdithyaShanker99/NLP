{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_hh = np.random.standard_normal((3,2))\n",
    "w_hx = np.random.standard_normal((3,3))\n",
    "h_t_prev = np.random.standard_normal((2,1))\n",
    "x_t = np.random.standard_normal((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_1 = np.hstack((w_hh, w_hx))\n",
    "\n",
    "stack_2 = np.vstack((h_t_prev, x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32319683]\n",
      " [-0.6577149 ]\n",
      " [ 4.61825108]]\n",
      "[[ 0.32319683]\n",
      " [-0.6577149 ]\n",
      " [ 4.61825108]]\n",
      "[[-0.56228753]\n",
      " [-1.01283112]\n",
      " [ 0.31424733]\n",
      " [-0.90802408]\n",
      " [-1.4123037 ]]\n",
      "[[-0.56228753]\n",
      " [-1.01283112]\n",
      " [ 0.31424733]\n",
      " [-0.90802408]\n",
      " [-1.4123037 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.matmul(np.hstack((w_hh, w_hx)), np.vstack((h_t_prev, x_t))))\n",
    "print(np.matmul(stack_1,stack_2))\n",
    "print(stack_2)\n",
    "print(np.concatenate([h_t_prev, x_t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "from time import perf_counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)                 # Random seed, so your results match ours\n",
    "emb = 128                       # Embedding size\n",
    "T = 256                         # Length of sequence\n",
    "h_dim = 16                      # Hidden state dimension\n",
    "h_0 = np.zeros((h_dim, 1))     \n",
    " \n",
    "w1 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w2 = random.standard_normal((h_dim, emb + h_dim))\n",
    "w3 = random.standard_normal((h_dim, emb + h_dim))\n",
    "\n",
    "b1 = random.standard_normal((h_dim, 1))\n",
    "b2 = random.standard_normal((h_dim, 1))\n",
    "b3 = random.standard_normal((h_dim, 1))\n",
    "\n",
    "X = random.standard_normal((T, emb, 1))\n",
    "\n",
    "weights_vanilla = [w1, b1]\n",
    "weights_GRU = [w1.copy(), w2, w3, b1.copy(), b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_RNN(inputs, weights):\n",
    "    x, ht = inputs\n",
    "    wh, bh = weights\n",
    "    \n",
    "    ht = np.matmul(wh, np.vstack((ht, x)))+bh\n",
    "    ht = sigmoid(ht)\n",
    "\n",
    "    y = ht\n",
    "    #print(ht)\n",
    "    return y,ht \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_GRU_RNN(inputs, weights):\n",
    "    x, ht = inputs\n",
    "    wu,wr,wh, bu,br,bh = weights\n",
    "\n",
    "    r = sigmoid(np.matmul(wr, np.vstack((ht, x)))+br)\n",
    "    u = sigmoid(np.matmul(wu, np.vstack((ht, x)))+bu)\n",
    "    ct = np.tanh(np.matmul(wh, np.concatenate([r * ht, x]))+bh)\n",
    "\n",
    "    #print(f'{u}\\n+\\n{r}\\n+\\n{ct}')\n",
    "    \n",
    "    ht = u*ct + (1-u) * ht\n",
    "    y = ht\n",
    "\n",
    "    return y,ht \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 9.77779014e-01],\n",
      "       [-9.97986240e-01],\n",
      "       [-5.19958083e-01],\n",
      "       [-9.99999886e-01],\n",
      "       [-9.99707004e-01],\n",
      "       [-3.02197037e-04],\n",
      "       [-9.58733503e-01],\n",
      "       [ 2.10804828e-02],\n",
      "       [ 9.77365398e-05],\n",
      "       [ 9.99833090e-01],\n",
      "       [ 1.63200940e-08],\n",
      "       [ 8.51874303e-01],\n",
      "       [ 5.21399924e-02],\n",
      "       [ 2.15495959e-02],\n",
      "       [ 9.99878828e-01],\n",
      "       [ 9.77165472e-01]]), array([[ 9.77779014e-01],\n",
      "       [-9.97986240e-01],\n",
      "       [-5.19958083e-01],\n",
      "       [-9.99999886e-01],\n",
      "       [-9.99707004e-01],\n",
      "       [-3.02197037e-04],\n",
      "       [-9.58733503e-01],\n",
      "       [ 2.10804828e-02],\n",
      "       [ 9.77365398e-05],\n",
      "       [ 9.99833090e-01],\n",
      "       [ 1.63200940e-08],\n",
      "       [ 8.51874303e-01],\n",
      "       [ 5.21399924e-02],\n",
      "       [ 2.15495959e-02],\n",
      "       [ 9.99878828e-01],\n",
      "       [ 9.77165472e-01]]))\n"
     ]
    }
   ],
   "source": [
    "print(forward_GRU_RNN([X[1], h_0], weights_GRU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(function, elems, weights, initializer=h_0):\n",
    "    cur_value = initializer\n",
    "    ys = []\n",
    "    for x in elems:\n",
    "        y,cur_value = function([x,cur_value],weights)\n",
    "        ys.append(y)\n",
    "    return ys,cur_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ys: 256\n",
      "Shape of each y within ys: (16, 1)\n",
      "Shape of h_T: (16, 1)\n"
     ]
    }
   ],
   "source": [
    "ys, h_T = scan(forward_RNN, X, weights_vanilla, h_0)\n",
    "\n",
    "print(f\"Length of ys: {len(ys)}\")\n",
    "print(f\"Shape of each y within ys: {ys[0].shape}\")\n",
    "print(f\"Shape of h_T: {h_T.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 6.16ms to run the forward method for the vanilla RNN.\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_RNN, X, weights_vanilla, h_0)\n",
    "toc = perf_counter()\n",
    "RNN_time=(toc-tic)*1000\n",
    "print (f\"It took {RNN_time:.2f}ms to run the forward method for the vanilla RNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.28ms to run the forward method for the GRU.\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "ys, h_T = scan(forward_GRU_RNN, X, weights_GRU, h_0)\n",
    "toc = perf_counter()\n",
    "GRU_time=(toc-tic)*1000\n",
    "print (f\"It took {GRU_time:.2f}ms to run the forward method for the GRU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GRU = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(256, return_sequences=True, name='GRU_1_returns_seq'),\n",
    "    tf.keras.layers.GRU(128, return_sequences=True, name='GRU_2_returns_seq'),\n",
    "    tf.keras.layers.GRU(64, name='GRU_3_returns_last_only'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (\u001b[38;5;33mGRU\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    model_GRU.summary()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">228,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)          │       \u001b[38;5;34m228,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_2_returns_seq (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)          │       \u001b[38;5;34m148,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_3_returns_last_only (\u001b[38;5;33mGRU\u001b[0m)   │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │        \u001b[38;5;34m37,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m10\u001b[0m)               │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,986</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m414,986\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">414,986</span> (1.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m414,986\u001b[0m (1.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember these three numbers and follow them further through the notebook\n",
    "batch_size = 60\n",
    "sequence_length = 50\n",
    "word_vector_length = 40\n",
    "\n",
    "input_data = tf.random.normal([batch_size, sequence_length, word_vector_length])\n",
    "\n",
    "prediction = model_GRU(input_data)\n",
    "\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "BENVOLIO\tHere were the servants of your adversary,\n",
      "And yours, close fighting ere I did approach:\n",
      "I drew to part them: in the instant came\n",
      "The fiery Tybalt, with his sword prepared,\n",
      "Which, as he breathed defiance to my ears,\n",
      "He swung about his head and cut the winds,\n",
      "Who nothing hurt withal hiss'd him in scorn:\n",
      "While we were interchanging thrusts and blows,\n"
     ]
    }
   ],
   "source": [
    "dirname = 'data/'\n",
    "filename = 'shakespeare_data.txt'\n",
    "lines = [] # storing all the lines in a variable. \n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(os.path.join(dirname, filename)) as files:\n",
    "    for line in files:        \n",
    "        pure_line = line.strip()\n",
    "        if pure_line:\n",
    "            lines.append(pure_line)\n",
    "            \n",
    "n_lines = len(lines)\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(\"\\n\".join(lines[506:514]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "[UNK]  \t \n",
      "   ! $ & ' ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z |\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(lines):\n",
    "    corpus = (\"\\n\".join(lines))\n",
    "    vocab = sorted(set(corpus))\n",
    "    vocab.insert(0,\"[UNK]\") \n",
    "    vocab.insert(1,\"\") \n",
    "    return vocab\n",
    "vocab = build_vocabulary(lines)\n",
    "print(len(vocab))\n",
    "print(\" \".join(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([55 56 57  4 78 79 80], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "def convert_text_to_tensor(text,vocab):\n",
    "    chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\n",
    "    return  tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)(chars)\n",
    "tmp = convert_text_to_tensor(\"abc xyz\", vocab)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'abc xyz'\n"
     ]
    }
   ],
   "source": [
    "def convert_tensor_to_text(tensor, vocab):\n",
    "    chars_from_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None, invert=True)\n",
    "    return tf.strings.reduce_join(chars_from_ids(tensor), axis=-1).numpy()\n",
    "print(convert_tensor_to_text(tmp, vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = lines[:-1000]\n",
    "eval_lines = lines[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'], ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])\n"
     ]
    }
   ],
   "source": [
    "def test_train_split(sequence):\n",
    "    return sequence[:-1], sequence[1:]\n",
    "print(test_train_split(list(\"Tensorflow\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(vocab, lines, seq_length=100, batch_size=64, BUFFER_SIZE = 10000):\n",
    "\n",
    "    line  = \"\\n\".join(lines)\n",
    "    all_ids = convert_text_to_tensor(line, vocab)\n",
    "    ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "    data_generator = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "    dataset_xy = data_generator.map(test_train_split)\n",
    "    dataset = (                                   \n",
    "        dataset_xy                                \n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(batch_size, drop_remainder=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "        )            \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = generate_dataset(vocab, train_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
    "        tf.keras.layers.GRU(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size, activation=tf.nn.log_softmax)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "vocab_size = 82  # Adjust as needed\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "\n",
    "model = create_gru_model(vocab_size, embedding_dim, rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,182,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m82\u001b[0m)        │        \u001b[38;5;34m42,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,778</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,245,778\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,778</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,245,778\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 100))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [70 65 63 68 73  4 59 68 69 77  4 55 56 69 75 74  4 79 69 75 25  4 62 59\n",
      " 72 59  3 79 69 75  8 66 66  4 73 77 59 55 74  4 60 69 72  8 74 13  3 53\n",
      " 37 68 69 57 65 63 68 61  4 77 63 74 62 63 68 54  3 37 68 69 57 65 11  3\n",
      " 65 68 69 57 65  5  4 49 62 69  8 73  4 74 62 59 72 59 11  4 63 68  4 74\n",
      " 62 59  4 69]\n",
      "\n",
      " (1, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input: \", input_example_batch[0].numpy()) # Lets use only the first sequence on the batch\n",
    "    example_batch_predictions = model(tf.constant([input_example_batch[0].numpy()]))\n",
    "    print(\"\\n\",example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.3906965, -4.391806 , -4.418195 , -4.410832 , -4.3922668,\n",
       "       -4.396673 , -4.411633 , -4.4147205, -4.416295 , -4.4076157,\n",
       "       -4.416847 , -4.3992734, -4.3920093, -4.397013 , -4.397345 ,\n",
       "       -4.4045177, -4.417554 , -4.4087577, -4.4097695, -4.400878 ,\n",
       "       -4.406688 , -4.41367  , -4.41644  , -4.4084888, -4.4333525,\n",
       "       -4.384691 , -4.38563  , -4.3952007, -4.4112525, -4.3841023,\n",
       "       -4.406918 , -4.398651 , -4.4046144, -4.3827014, -4.41077  ,\n",
       "       -4.4254317, -4.4106174, -4.4145975, -4.4237037, -4.410116 ,\n",
       "       -4.4033895, -4.438456 , -4.423766 , -4.4096932, -4.4143467,\n",
       "       -4.405991 , -4.413774 , -4.4011264, -4.4183707, -4.4106135,\n",
       "       -4.4102964, -4.388678 , -4.432466 , -4.4145074, -4.388995 ,\n",
       "       -4.3939414, -4.411776 , -4.4152703, -4.39919  , -4.411476 ,\n",
       "       -4.4035416, -4.40768  , -4.4161153, -4.395751 , -4.381609 ,\n",
       "       -4.399002 , -4.421347 , -4.417153 , -4.391004 , -4.4012356,\n",
       "       -4.4205   , -4.3987775, -4.4220033, -4.39702  , -4.4121046,\n",
       "       -4.4108562, -4.39868  , -4.4177012, -4.4072905, -4.405117 ,\n",
       "       -4.397373 , -4.4063783], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0][99].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 73 17 12 24 17 25 12 12 18 25 69 21 64 29 58 51 27 54 29 58 25 29 25\n",
      " 47 25 58  1 54 58 44 17 17 17 17 69 25 69 18 25 49 80 47  5 18 33 80 74\n",
      "  4 12 26 19 73 42 12 36 62 69 17 17 17 17 66 12 12 79 12 26 19 73 50 32\n",
      " 73 12 12 19 73 60 70 29 29 29  5 69 17 17 17 58 18 25 50 25 17 12 71 17\n",
      " 47 33 25 64]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.math.argmax(example_batch_predictions[0], axis=1)\n",
    "print(sampled_indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"pkins enow about you; here\\nyou'll sweat for't.\\n[Knocking within]\\nKnock,\\nknock! Who's there, in the o\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'.s3-:3;--4;o7jCdYA]Cd;C;U;d]dR3333o;o4;WzU!4Gzt -?5sP-Jho3333l--y-?5sXFs--5sfpCCC!o333d4;X;3-q3UG;j'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", convert_tensor_to_text(input_example_batch[0], vocab))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", convert_tensor_to_text(sampled_indices, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.00125)\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 233ms/step - loss: 2.1975\n",
      "Epoch 2/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 243ms/step - loss: 1.4679\n",
      "Epoch 3/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 230ms/step - loss: 1.3776\n",
      "Epoch 4/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 231ms/step - loss: 1.3365\n",
      "Epoch 5/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 231ms/step - loss: 1.3115\n",
      "Epoch 6/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 229ms/step - loss: 1.2928\n",
      "Epoch 7/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 231ms/step - loss: 1.2807\n",
      "Epoch 8/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 230ms/step - loss: 1.2691\n",
      "Epoch 9/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 236ms/step - loss: 1.2590\n",
      "Epoch 10/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 228ms/step - loss: 1.2524\n",
      "Epoch 11/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 234ms/step - loss: 1.2462\n",
      "Epoch 12/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 240ms/step - loss: 1.2401\n",
      "Epoch 13/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 243ms/step - loss: 1.2346\n",
      "Epoch 14/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 240ms/step - loss: 1.2300\n",
      "Epoch 15/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 235ms/step - loss: 1.2268\n",
      "Epoch 16/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 234ms/step - loss: 1.2243\n",
      "Epoch 17/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 234ms/step - loss: 1.2200\n",
      "Epoch 18/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 234ms/step - loss: 1.2179\n",
      "Epoch 19/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 225ms/step - loss: 1.2151\n",
      "Epoch 20/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 224ms/step - loss: 1.2133\n",
      "Epoch 21/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 223ms/step - loss: 1.2117\n",
      "Epoch 22/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 221ms/step - loss: 1.2099\n",
      "Epoch 23/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 219ms/step - loss: 1.2093\n",
      "Epoch 24/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 223ms/step - loss: 1.2081\n",
      "Epoch 25/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 224ms/step - loss: 1.2066\n",
      "Epoch 26/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 219ms/step - loss: 1.2056\n",
      "Epoch 27/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 221ms/step - loss: 1.2056\n",
      "Epoch 28/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 221ms/step - loss: 1.2051\n",
      "Epoch 29/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 220ms/step - loss: 1.2056\n",
      "Epoch 30/30\n",
      "\u001b[1m790/790\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 224ms/step - loss: 1.2033\n"
     ]
    }
   ],
   "source": [
    "Epochs = 30\n",
    "model = compile_model(model)\n",
    "history = model.fit(dataset, epochs = Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"saved.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"saved.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,066</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,182,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m82\u001b[0m)        │        \u001b[38;5;34m42,066\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,737,336</span> (14.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,737,336\u001b[0m (14.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,778</span> (4.75 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,245,778\u001b[0m (4.75 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,491,558</span> (9.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,491,558\u001b[0m (9.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [75 72  4 70 75 72 73 59  4 74 69  4 74 62 59  4 69 75 74 73 63 58 59  4\n",
      " 69 60  4 62 63 73  4 62 55 68 58 11  3 55 68 58  4 68 69  4 67 69 72 59\n",
      "  4 55 58 69 13  4 44 59 67 59 67 56 59 72  4  8 73 74 69 68 59 58 11  8\n",
      "  4 55 68 58  4  8 60 66 55 79 59 58  4 55 66 63 76 59 13  8  3 45 62 59\n",
      " 70 62 59 72]\n",
      "\n",
      " (1, 100, 82) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    print(\"Input: \", input_example_batch[0].numpy()) # Lets use only the first sequence on the batch\n",
    "    example_batch_predictions = model(tf.constant([input_example_batch[0].numpy()]))\n",
    "    print(\"\\n\",example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72  4 66 66 72 70 59 11 74 62  4 74 62 59 59 57 74 74 77 63 58 59  4 69\n",
      " 60  4 74 59 73  4 70 59 68 58 11  3 27 68 58  4 74 69 74 67 55 72 59  4\n",
      " 74 58 69 72  3 46 59 74 59 67 56 59 72  4 74 74 57 69 68 59 58  4  4  4\n",
      " 55 68 58  4 74 74 69 55 77 59 58  4 55 68 72 76 59 11  3  3 45 35 59  4\n",
      " 62 59 72 58]\n"
     ]
    }
   ],
   "source": [
    "sampled_indices = tf.math.argmax(example_batch_predictions[0], axis=1)\n",
    "print(sampled_indices.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b\"ur purse to the outside of his hand,\\nand no more ado. Remember 'stoned,' and 'flayed alive.'\\nShepher\"\n",
      "\n",
      "Next Char Predictions:\n",
      " b'r llrpe,th theecttwide of tes pend,\\nAnd totmare tdor\\nTetember ttconed   and ttoawed anrve,\\n\\nSIe herd'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", convert_tensor_to_text(input_example_batch[0], vocab))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", convert_tensor_to_text(sampled_indices, vocab))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
