{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/adithyashanker/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adithyashanker/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from nltk.corpus import twitter_samples\n",
    "import random\n",
    "import numpy as np\n",
    "import math as m\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use predefined function ‘fileids()’ to see the content\n",
    "twitter_samples.fileids()\n",
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m@tonywhittaker Fabulous! Well we hope you all have a great day :-) ^KB\n",
      "\u001b[91m@smiffy Sorry to hear about your dogs :(\n"
     ]
    }
   ],
   "source": [
    "# print positive in greeen\n",
    "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
    "\n",
    "# print negative in red\n",
    "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
    "import re\n",
    "import string                              # for string operations\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "tweets = all_positive_tweets + all_negative_tweets ## Concatenate the lists. \n",
    "labels = np.append(np.ones((len(all_positive_tweets),1)), np.zeros((len(all_negative_tweets),1)), axis = 0)\n",
    "\n",
    "train_pos  = all_positive_tweets[:4000]\n",
    "train_neg  = all_negative_tweets[:4000]\n",
    "train_x = train_pos + train_neg \n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)), axis=0).reshape(-1)\n",
    "\n",
    "\n",
    "test_pos  = all_positive_tweets[1000:]\n",
    "test_neg  = all_negative_tweets[1000:]\n",
    "test_x = test_pos + test_neg\n",
    "test_y = np.append(np.ones(len(test_pos)),np.zeros(len(test_neg)), axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet) :\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "    cleaned_stemmed_tweet = []\n",
    "    for token in tweet_tokens:\n",
    "        if token not in stop_words and token not in punctuation :\n",
    "            cleaned_stemmed_tweet.append(stemmer.stem(token))\n",
    "    return cleaned_stemmed_tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def buildFrequencyTable(features_x,labels_list):\n",
    "    dictionary = {}\n",
    "    sum_pos = 0\n",
    "    sum_neg = 0\n",
    "    for i in range(len(features_x)) :\n",
    "        tokens = preprocess(features_x[i])\n",
    "        for token in tokens:\n",
    "            if token not in dictionary:\n",
    "                if labels_list[i] == 1:\n",
    "                    dictionary[token] = (1,0)\n",
    "                    sum_pos+=1\n",
    "                else:\n",
    "                    dictionary[token] = (0,1)\n",
    "                    sum_neg+=1\n",
    "            else:\n",
    "                if labels_list[i] == 1:\n",
    "                    dictionary[token] = (dictionary[token][0]+1,dictionary[token][1])\n",
    "                    sum_pos+=1\n",
    "                else:\n",
    "                    dictionary[token] = (dictionary[token][0], dictionary[token][1]+1)\n",
    "                    sum_neg+=1\n",
    "    return dictionary,sum_pos,sum_neg\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(dictionary,sum_pos, sum_neg, alpha):\n",
    "    for key in dictionary:\n",
    "        dictionary[key] = (dictionary[key][0]+alpha)/(sum_pos+len(dictionary)) , (dictionary[key][1]+alpha)/(sum_neg+len(dictionary))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'happi': (2, 1), 'learn': (1, 1), 'nlp': (1, 1), 'sad': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "x_temp = [\"I am happy because I am learning NLP I am happy, not sad\",\"I am sad, I am not learning NLP I am sad,not happy\"]\n",
    "temp_labels = [1,0]\n",
    "dictionary,sum_pos,sum_neg = buildFrequencyTable(x_temp,temp_labels)\n",
    "print(dictionary)\n",
    "dictionary = laplace_smoothing(dictionary,sum_pos,sum_neg,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_lambdas(dictionary) :\n",
    "    for key in dictionary:\n",
    "        dictionary[key] = (dictionary[key][0], dictionary[key][1], np.log(dictionary[key][0]/dictionary[key][1]))\n",
    "    return dictionary\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, logprior, tweet) :\n",
    "    tokens = preprocess(tweet)\n",
    "    prediction = 0\n",
    "    for token in dictionary :\n",
    "        prediction += dictionary[token][2]\n",
    "    return int((prediction+logprior)>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
